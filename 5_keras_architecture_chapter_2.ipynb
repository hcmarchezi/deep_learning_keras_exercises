{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "Multidimensional array or matrix which is the building block for symbolics computation on NN frameworks.\n",
    "**PS:** Read more about this since this concept should be well understood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing Models\n",
    "Models can be composed Sequentially (Sequencial API) or by Functioning Composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Defined Neural Network Layers\n",
    "* **keras.layers.core.Dense** - fully connected neural network layer\n",
    "\n",
    "Below are pre-defined recurrent layers:\n",
    "* **keras.layers.recurrent.Recurrent**\n",
    "* **keras.layers.recurrent.SimpleRNN**\n",
    "* **keras.layers.recurrent.GRU**\n",
    "* **keras.layers.recurrent.LSTM**\n",
    "\n",
    "Below are pre-defined convolutional layers:\n",
    "* **keras.layers.convolutional.Conv1D**\n",
    "* **keras.layers.convolutional.Conv2D**\n",
    "* **keras.layers.pooling.MaxPooling1D**\n",
    "* **keras.layers.pooling.MaxPooling2D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Regulization methods commonly used by parameters in Dense and Convolutional layers:\n",
    "* **kernel_regularizer:** Regularizer function applied to the weight matrix\n",
    "* **bias_regularizer:** Regularizer function applied to the bias vector\n",
    "* **activity_regularizer:** Regularizer function applied to the output of the layer (its activation)\n",
    "\n",
    "Additionally dropout is also a regularization method:\n",
    "* **keras.layers.core.Dropout(rate, noise_shape=None, seed=None)**\n",
    "\n",
    "As well as batch normalizatio layer: (ref = https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c )\n",
    "* **keras.layers.normalization.BatchNormalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "* **Sigmoid**\n",
    "* **Linear**\n",
    "* **Tanh**\n",
    "* **ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "### For Accuracy\n",
    "* **binary_accuracy** - for binary classification problems\n",
    "* **categorical_accuracy** - for multiple classification problems\n",
    "* **sparse_categorical_accuracy** - for sparse categorical\n",
    "* **top_k_categorical_accuracy** - success when prediction is within top k provided categories\n",
    "\n",
    "### For Errors\n",
    "* **mse** - mean squared error\n",
    "* **rmse** - root mean squared error\n",
    "* **mae** - mean absolut error\n",
    "* **mape** - mean absolut percentage error\n",
    "* **msle** - mesn squared logarithmic error\n",
    "\n",
    "### Hinge Loss\n",
    "* **hinge** - used for maximum margin classifier training such as SVM - https://en.wikipedia.org/wiki/Hinge_loss\n",
    "\n",
    "### Class Loss\n",
    "* **cross-entropy**\n",
    "* **categorical-cross-entropy**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "* **SGD** - stochastic gradient descent\n",
    "* **RMSprop** - adaptive learning method\n",
    "* **Adam** - adaptative moment estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Callbacks\n",
    "* **keras.callbacks.EarlyStopping**\n",
    " * Stops the training process whenever a metrics reaches a certain variation level\n",
    "* **create your own callback**\n",
    " * Ex: class LossHistory(keras.callbacks.Callback): (implement required methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoint\n",
    "* Process of saving the model state at regular intervals for recovery purpose in case of failure or analysis\n",
    "    * keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Neural Network While Training\n",
    "\n",
    "### With TensorBoard\n",
    "* keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "* cmd-ine: tensorboard --logdir=/full_path_to_your_logs\n",
    "\n",
    "### With Quiver\n",
    "* Visualizaing training for CNN\n",
    "* https://github.com/jakebian/quiver\n",
    "* pip install quiver_engine\n",
    "* code\n",
    "<pre>\n",
    "from quiver_engine import server\n",
    "server.launch(model)\n",
    "</pre>\n",
    "* launch server: localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
